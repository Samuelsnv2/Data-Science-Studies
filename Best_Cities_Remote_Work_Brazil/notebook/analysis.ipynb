{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Cities for Remote Work in Brazil - Analysis\n",
    "\n",
    "This notebook analyzes various factors to determine the best cities for remote work in Brazil, including:\n",
    "* Internet quality/reliability\n",
    "* Cost of living\n",
    "* Quality of life\n",
    "* Safety\n",
    "* Climate\n",
    "* Access to coworking spaces\n",
    "* Transportation infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexpress\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpx\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Set visualization styles\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data from scraped JSON files\n",
    "def load_data(data_dir='../data'):\n",
    "    # Check if consolidated CSV exists and load it\n",
    "    csv_path = os.path.join(data_dir, 'brazil_remote_work_cities.csv')\n",
    "    if os.path.exists(csv_path):\n",
    "        print(f\"Loading consolidated data from {csv_path}\")\n",
    "        return pd.read_csv(csv_path)\n",
    "    \n",
    "    # If not, load and combine individual JSON files\n",
    "    print(\"Consolidated CSV not found. Loading individual data files...\")\n",
    "    \n",
    "    # Define file paths for each category\n",
    "    data_files = {\n",
    "        'internet': os.path.join(data_dir, 'internet_quality.json'),\n",
    "        'cost': os.path.join(data_dir, 'cost_of_living.json'),\n",
    "        'safety': os.path.join(data_dir, 'safety_data.json'),\n",
    "        'climate': os.path.join(data_dir, 'climate_data.json'),\n",
    "        'coworking': os.path.join(data_dir, 'coworking_data.json'),\n",
    "        'transport': os.path.join(data_dir, 'transportation_data.json'),\n",
    "        'quality': os.path.join(data_dir, 'quality_of_life.json')\n",
    "    }\n",
    "    \n",
    "    # Load each JSON file\n",
    "    data_dict = {}\n",
    "    for category, filepath in data_files.items():\n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                loaded_data = json.load(f)\n",
    "                data_dict[category] = loaded_data['data']\n",
    "        else:\n",
    "            print(f\"Warning: {filepath} not found.\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    cities = list(data_dict['internet'].keys()) if 'internet' in data_dict else []\n",
    "    if not cities:\n",
    "        raise ValueError(\"No cities found in data files\")\n",
    "    \n",
    "    city_data = []\n",
    "    for city in cities:\n",
    "        city_row = {'city': city}\n",
    "        \n",
    "        # Add data from each category\n",
    "        for category, data in data_dict.items():\n",
    "            if city in data:\n",
    "                # Flatten nested dictionaries and prefix keys with category name\n",
    "                for key, value in data[city].items():\n",
    "                    if not isinstance(value, (dict, list)):\n",
    "                        city_row[f\"{category}_{key}\"] = value\n",
    "        \n",
    "        city_data.append(city_row)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(city_data)\n",
    "    \n",
    "    # Save as CSV for future use\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Created and saved consolidated data to {csv_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "try:\n",
    "    df = load_data()\n",
    "    print(f\"Loaded data for {len(df)} cities\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    print(\"Creating sample data for demonstration purposes\")\n",
    "    \n",
    "    # Create sample data if files don't exist\n",
    "    cities = ['S√£o Paulo', 'Rio de Janeiro', 'Bras√≠lia', 'Salvador', 'Fortaleza',\n",
    "              'Belo Horizonte', 'Manaus', 'Curitiba', 'Recife', 'Porto Alegre',\n",
    "              'Bel√©m', 'Goi√¢nia', 'Florian√≥polis', 'Natal', 'Vit√≥ria', 'Santos']\n",
    "    \n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'city': cities,\n",
    "        'internet_avg_download_mbps': np.random.uniform(30, 150, len(cities)),\n",
    "        'internet_fiber_availability': np.random.uniform(0.3, 0.9, len(cities)),\n",
    "        'cost_monthly_rent_1br_center': np.random.randint(1000, 3500, len(cities)),\n",
    "        'cost_index': np.random.uniform(30, 70, len(cities)),\n",
    "        'safety_index': np.random.uniform(30, 80, len(cities)),\n",
    "        'safety_crime_index': np.random.uniform(20, 70, len(cities)),\n",
    "        'climate_avg_annual_temp': np.random.uniform(18, 30, len(cities)),\n",
    "        'climate_comfort_index': np.random.uniform(40, 85, len(cities)),\n",
    "        'coworking_total_spaces': np.random.randint(5, 100, len(cities)),\n",
    "        'coworking_avg_monthly_price': np.random.randint(350, 1000, len(cities)),\n",
    "        'transport_public_transit_score': np.random.uniform(30, 90, len(cities)),\n",
    "        'transport_walkability_score': np.random.uniform(40, 85, len(cities)),\n",
    "        'quality_hdi': np.random.uniform(0.65, 0.85, len(cities)),\n",
    "        'quality_healthcare_quality': np.random.uniform(50, 90, len(cities)),\n",
    "        'quality_overall_happiness_index': np.random.uniform(5, 9, len(cities))\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Basic statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle any missing values\n",
    "# For this analysis, we'll use simple imputation with mean values\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "for col in numeric_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        print(f\"Imputing missing values for {col}\")\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "# Check if all missing values are handled\n",
    "print(f\"Remaining missing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create derived metrics and normalize data\n",
    "\n",
    "# 1. Internet Quality Score (higher is better)\n",
    "if 'internet_avg_download_mbps' in df.columns and 'internet_fiber_availability' in df.columns:\n",
    "    df['internet_quality_score'] = (df['internet_avg_download_mbps'] / 10) * 0.7 + (df['internet_fiber_availability'] * 100) * 0.3\n",
    "\n",
    "# 2. Cost of Living Score (lower is better, so we invert it)\n",
    "if 'cost_index' in df.columns:\n",
    "    df['cost_living_score'] = 100 - df['cost_index']\n",
    "\n",
    "# 3. Safety Score (already have safety_index)\n",
    "if 'safety_crime_index' in df.columns and 'safety_index' not in df.columns:\n",
    "    df['safety_index'] = 100 - df['safety_crime_index']\n",
    "\n",
    "# 4. Climate Score (already have climate_comfort_index)\n",
    "# We'll use it directly\n",
    "\n",
    "# 5. Coworking Score (availability and affordability)\n",
    "if 'coworking_total_spaces' in df.columns and 'coworking_avg_monthly_price' in df.columns:\n",
    "    # Normalize spaces to 0-100 range\n",
    "    max_spaces = df['coworking_total_spaces'].max()\n",
    "    df['normalized_spaces'] = (df['coworking_total_spaces'] / max_spaces) * 100\n",
    "    \n",
    "    # Normalize price (lower is better, so invert)\n",
    "    max_price = df['coworking_avg_monthly_price'].max()\n",
    "    min_price = df['coworking_avg_monthly_price'].min()\n",
    "    df['normalized_price'] = 100 - ((df['coworking_avg_monthly_price'] - min_price) / (max_price - min_price) * 100)\n",
    "    \n",
    "    # Combine (70% weight on availability, 30% on affordability)\n",
    "    df['coworking_score'] = df['normalized_spaces'] * 0.7 + df['normalized_price'] * 0.3\n",
    "\n",
    "# 6. Transportation Score\n",
    "if 'transport_public_transit_score' in df.columns and 'transport_walkability_score' in df.columns:\n",
    "    df['transportation_score'] = df['transport_public_transit_score'] * 0.6 + df['transport_walkability_score'] * 0.4\n",
    "\n",
    "# 7. Quality of Life Score\n",
    "quality_cols = [col for col in df.columns if col.startswith('quality_') and col != 'quality_overall_happiness_index']\n",
    "if quality_cols:\n",
    "    # Normalize HDI to 0-100 scale if present\n",
    "    if 'quality_hdi' in df.columns:\n",
    "        df['quality_hdi_norm'] = (df['quality_hdi'] - 0.5) * 200  # Convert 0.5-1.0 range to 0-100\n",
    "        quality_cols.remove('quality_hdi')\n",
    "        quality_cols.append('quality_hdi_norm')\n",
    "    \n",
    "    # If we have normalized quality columns, create a composite score\n",
    "    if quality_cols:\n",
    "        df['quality_life_score'] = df[quality_cols].mean(axis=1)\n",
    "    elif 'quality_overall_happiness_index' in df.columns:\n",
    "        # If we only have happiness index (1-10 scale), convert to 0-100\n",
    "        df['quality_life_score'] = df['quality_overall_happiness_index'] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with just our composite scores for easier analysis\n",
    "score_columns = [\n",
    "    'internet_quality_score', \n",
    "    'cost_living_score', \n",
    "    'safety_index', \n",
    "    'climate_comfort_index', \n",
    "    'coworking_score', \n",
    "    'transportation_score', \n",
    "    'quality_life_score'\n",
    "]\n",
    "\n",
    "# Check which score columns actually exist in our dataframe\n",
    "available_scores = [col for col in score_columns if col in df.columns]\n",
    "\n",
    "# Create scores dataframe with only available columns\n",
    "scores_df = df[['city'] + available_scores].copy()\n",
    "\n",
    "# Display the scores\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Factor Analysis: Internet Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Internet Quality\n",
    "internet_cols = [col for col in df.columns if col.startswith('internet_')]\n",
    "\n",
    "if internet_cols:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    if 'internet_avg_download_mbps' in df.columns:\n",
    "        # Sort by download speed\n",
    "        internet_df = df[['city', 'internet_avg_download_mbps']].sort_values('internet_avg_download_mbps', ascending=False)\n",
    "        \n",
    "        # Plot download speeds\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.barplot(x='internet_avg_download_mbps', y='city', data=internet_df)\n",
    "        plt.title('Average Download Speed by City (Mbps)')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    if 'internet_quality_score' in df.columns:\n",
    "        # Plot overall internet quality score\n",
    "        plt.subplot(1, 2, 2)\n",
    "        quality_df = df[['city', 'internet_quality_score']].sort_values('internet_quality_score', ascending=False)\n",
    "        sns.barplot(x='internet_quality_score', y='city', data=quality_df)\n",
    "        plt.title('Internet Quality Score by City')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show top 3 cities for internet quality\n",
    "    if 'internet_quality_score' in df.columns:\n",
    "        top_internet = df.sort_values('internet_quality_score', ascending=False)[['city', 'internet_quality_score']].head(3)\n",
    "        print(\"Top 3 Cities for Internet Quality:\")\n",
    "        print(top_internet)\n",
    "else:\n",
    "    print(\"No internet quality data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Factor Analysis: Cost of Living"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Cost of Living\n",
    "cost_cols = [col for col in df.columns if col.startswith('cost_')]\n",
    "\n",
    "if cost_cols:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    if 'cost_monthly_rent_1br_center' in df.columns:\n",
    "        # Sort by rent cost (ascending for better visualization of cheapest cities)\n",
    "        rent_df = df[['city', 'cost_monthly_rent_1br_center']].sort_values('cost_monthly_rent_1br_center')\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.barplot(x='cost_monthly_rent_1br_center', y='city', data=rent_df)\n",
    "        plt.title('Monthly Rent for 1BR Apartment (City Center, BRL)')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    if 'cost_living_score' in df.columns:\n",
    "        # Plot cost of living score (higher score means more affordable)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        cost_score_df = df[['city', 'cost_living_score']].sort_values('cost_living_score', ascending=False)\n",
    "        sns.barplot(x='cost_living_score', y='city', data=cost_score_df)\n",
    "        plt.title('Cost of Living Score (Higher = More Affordable)')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show top 3 most affordable cities\n",
    "    if 'cost_living_score' in df.columns:\n",
    "        top_affordable = df.sort_values('cost_living_score', ascending=False)[['city', 'cost_living_score']].head(3)\n",
    "        print(\"Top 3 Most Affordable Cities:\")\n",
    "        print(top_affordable)\n",
    "else:\n",
    "    print(\"No cost of living data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Factor Analysis: Safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Safety\n",
    "safety_cols = [col for col in df.columns if col.startswith('safety_')]\n",
    "\n",
    "if safety_cols:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    if 'safety_index' in df.columns:\n",
    "        # Sort by safety index\n",
    "        safety_df = df[['city', 'safety_index']].sort_values('safety_index', ascending=False)\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.barplot(x='safety_index', y='city', data=safety_df)\n",
    "        plt.title('Safety Index by City')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    if 'safety_crime_index' in df.columns:\n",
    "        # Plot crime index (lower is better)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        crime_df = df[['city', 'safety_crime_index']].sort_values('safety_crime_index')\n",
    "        sns.barplot(x='safety_crime_index', y='city', data=crime_df)\n",
    "        plt.title('Crime Index by City (Lower is Better)')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show top 3 safest cities\n",
    "    if 'safety_index' in df.columns:\n",
    "        top_safety = df.sort_values('safety_index', ascending=False)[['city', 'safety_index']].head(3)\n",
    "        print(\"Top 3 Safest Cities:\")\n",
    "        print(top_safety)\n",
    "else:\n",
    "    print(\"No safety data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Factor Analysis: Climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Climate\n",
    "climate_cols = [col for col in df.columns if col.startswith('climate_')]\n",
    "\n",
    "if climate_cols:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    if 'climate_avg_annual_temp' in df.columns:\n",
    "        # Sort by average temperature\n",
    "        temp_df = df[['city', 'climate_avg_annual_temp']].sort_values('climate_avg_annual_temp')\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.barplot(x='climate_avg_annual_temp', y='city', data=temp_df)\n",
    "        plt.title('Average Annual Temperature (¬∞C)')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    if 'climate_comfort_index' in df.columns:\n",
    "        # Plot climate comfort index\n",
    "        plt.subplot(1, 2, 2)\n",
    "        comfort_df = df[['city', 'climate_comfort_index']].sort_values('climate_comfort_index', ascending=False)\n",
    "        sns.barplot(x='climate_comfort_index', y='city', data=comfort_df)\n",
    "        plt.title('Climate Comfort Index')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show top 3 cities with best climate\n",
    "    if 'climate_comfort_index' in df.columns:\n",
    "        top_climate = df.sort_values('climate_comfort_index', ascending=False)[['city', 'climate_comfort_index']].head(3)\n",
    "        print(\"Top 3 Cities with Best Climate:\")\n",
    "        print(top_climate)\n",
    "else:\n",
    "    print(\"No climate data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Factor Analysis: Coworking Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Coworking Spaces\n",
    "coworking_cols = [col for col in df.columns if col.startswith('coworking_')]\n",
    "\n",
    "if coworking_cols:\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    if 'coworking_total_spaces' in df.columns:\n",
    "        # Sort by total spaces\n",
    "        spaces_df = df[['city', 'coworking_total_spaces']].sort_values('coworking_total_spaces', ascending=False)\n",
    "        \n",
    "        plt.subplot(2, 1, 1)\n",
    "        sns.barplot(x='coworking_total_spaces', y='city', data=spaces_df)\n",
    "        plt.title('Number of Coworking Spaces')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    if 'coworking_avg_monthly_price' in df.columns:\n",
    "        # Sort by average price (ascending for better visualization of cheaper options)\n",
    "        price_df = df[['city', 'coworking_avg_monthly_price']].sort_values('coworking_avg_monthly_price')\n",
    "        \n",
    "        plt.subplot(2, 1, 2)\n",
    "        sns.barplot(x='coworking_avg_monthly_price', y='city', data=price_df)\n",
    "        plt.title('Average Monthly Price for Coworking Space (BRL)')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show top 3 cities for coworking\n",
    "    if 'coworking_score' in df.columns:\n",
    "        top_coworking = df.sort_values('coworking_score', ascending=False)[['city', 'coworking_score']].head(3)\n",
    "        print(\"Top 3 Cities for Coworking Spaces:\")\n",
    "        print(top_coworking)\n",
    "else:\n",
    "    print(\"No coworking space data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Factor Analysis: Transportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Transportation\n",
    "transport_cols = [col for col in df.columns if col.startswith('transport_')]\n",
    "\n",
    "if transport_cols:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    if 'transport_public_transit_score' in df.columns and 'transport_walkability_score' in df.columns:\n",
    "        # Create a plot comparing public transit and walkability\n",
    "        transport_df = df[['city', 'transport_public_transit_score', 'transport_walkability_score']]\n",
    "        \n",
    "        # Sort by combined score\n",
    "        transport_df['combined'] = transport_df['transport_public_transit_score'] + transport_df['transport_walkability_score']\n",
    "        transport_df = transport_df.sort_values('combined', ascending=False).drop('combined', axis=1)\n",
    "        \n",
    "        # Reshape for plotting\n",
    "        transport_long = pd.melt(transport_df, id_vars=['city'], var_name='metric', value_name='score')\n",
    "        \n",
    "        # Rename for better labels\n",
    "        transport_long['metric'] = transport_long['metric'].str.replace('transport_', '').str.replace('_score', '')\n",
    "        transport_long['metric'] = transport_long['metric'].str.replace('_', ' ').str.title()\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.barplot(x='score', y='city', hue='metric', data=transport_long)\n",
    "        plt.title('Transportation Metrics by City')\n",
    "        plt.legend(title='')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    if 'transportation_score' in df.columns:\n",
    "        # Plot overall transportation score\n",
    "        plt.subplot(1, 2, 2)\n",
    "        trans_score_df = df[['city', 'transportation_score']].sort_values('transportation_score', ascending=False)\n",
    "        sns.barplot(x='transportation_score', y='city', data=trans_score_df)\n",
    "        plt.title('Overall Transportation Score')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show top 3 cities for transportation\n",
    "    if 'transportation_score' in df.columns:\n",
    "        top_transport = df.sort_values('transportation_score', ascending=False)[['city', 'transportation_score']].head(3)\n",
    "        print('Top 3 Cities for Transportation:')\n",
    "        print(top_transport)\n",
    "else:\n",
    "    print('No transportation data available for analysis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Factor Analysis: Quality of Life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Quality of Life\n",
    "quality_cols = [col for col in df.columns if col.startswith('quality_')]\n",
    "\n",
    "if quality_cols:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    if 'quality_hdi' in df.columns:\n",
    "        # Sort by HDI\n",
    "        hdi_df = df[['city', 'quality_hdi']].sort_values('quality_hdi', ascending=False)\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.barplot(x='quality_hdi', y='city', data=hdi_df)\n",
    "        plt.title('Human Development Index (HDI)')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    if 'quality_life_score' in df.columns:\n",
    "        # Plot quality of life score\n",
    "        plt.subplot(1, 2, 2)\n",
    "        qol_df = df[['city', 'quality_life_score']].sort_values('quality_life_score', ascending=False)\n",
    "        sns.barplot(x='quality_life_score', y='city', data=qol_df)\n",
    "        plt.title('Quality of Life Score')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show top 3 cities for quality of life\n",
    "    if 'quality_life_score' in df.columns:\n",
    "        top_quality = df.sort_values('quality_life_score', ascending=False)[['city', 'quality_life_score']].head(3)\n",
    "        print(\"Top 3 Cities for Quality of Life:\")\n",
    "        print(top_quality)\n",
    "else:\n",
    "    print(\"No quality of life data available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Comprehensive Analysis and City Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive ranking with weights for each factor\n",
    "\n",
    "# Define default weights (can be adjusted based on preferences)\n",
    "default_weights = {\n",
    "    'internet_quality_score': 0.20,  # Internet quality is crucial for remote work\n",
    "    'cost_living_score': 0.15,       # Cost of living is important for long-term sustainability\n",
    "    'safety_index': 0.15,            # Safety is a fundamental concern\n",
    "    'climate_comfort_index': 0.10,   # Climate affects day-to-day comfort\n",
    "    'coworking_score': 0.10,         # Access to working spaces\n",
    "    'transportation_score': 0.10,    # Ability to move around easily\n",
    "    'quality_life_score': 0.20       # Overall quality of life is crucial for happiness\n",
    "}\n",
    "\n",
    "# Function to calculate weighted scores\n",
    "def calculate_weighted_score(df, weights=default_weights):\n",
    "    # Create a copy to avoid modifying the original\n",
    "    score_df = df.copy()\n",
    "    \n",
    "    # Check which score columns are available\n",
    "    available_score_cols = [col for col in weights.keys() if col in score_df.columns]\n",
    "    \n",
    "    # Normalize weights for available columns\n",
    "    total_weight = sum(weights[col] for col in available_score_cols)\n",
    "    normalized_weights = {col: weights[col]/total_weight for col in available_score_cols}\n",
    "    \n",
    "    # Calculate weighted sum\n",
    "    score_df['total_score'] = 0\n",
    "    for col in available_score_cols:\n",
    "        score_df['total_score'] += score_df[col] * normalized_weights[col]\n",
    "    \n",
    "    # Round to 2 decimal places\n",
    "    score_df['total_score'] = score_df['total_score'].round(2)\n",
    "    \n",
    "    return score_df\n",
    "\n",
    "# Calculate weighted scores with default weights\n",
    "ranking_df = calculate_weighted_score(scores_df)\n",
    "\n",
    "# Display the final rankings\n",
    "final_ranking = ranking_df.sort_values('total_score', ascending=False)[['city', 'total_score']]\n",
    "print(\"Final Rankings - Best Cities for Remote Work in Brazil:\")\n",
    "print(final_ranking)\n",
    "\n",
    "# Visualize the top 10 cities\n",
    "plt.figure(figsize=(12, 8))\n",
    "top10 = final_ranking.head(10)\n",
    "sns.barplot(x='total_score', y='city', data=top10)\n",
    "plt.title('Top 10 Cities for Remote Work in Brazil')\n",
    "plt.xlabel('Total Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a radar chart to visualize the top 5 cities across all dimensions\n",
    "top5_cities = final_ranking.head(5)['city'].tolist()\n",
    "\n",
    "# Filter data for top 5 cities and only include score columns\n",
    "top5_df = scores_df[scores_df['city'].isin(top5_cities)]\n",
    "\n",
    "# Ensure all score columns are available and normalized between 0-100\n",
    "radar_cols = [col for col in score_columns if col in top5_df.columns]\n",
    "\n",
    "# Create radar chart using plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "for city in top5_cities:\n",
    "    city_data = top5_df[top5_df['city'] == city]\n",
    "    \n",
    "    # Get values for radar chart\n",
    "    values = city_data[radar_cols].values.flatten().tolist()\n",
    "    # Add the first value at the end to close the loop\n",
    "    values = values + [values[0]]\n",
    "    \n",
    "    # Prepare labels\n",
    "    labels = [col.replace('_', ' ').title().replace('Index', '').replace('Score', '') for col in radar_cols]\n",
    "    labels = labels + [labels[0]]\n",
    "    \n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=values,\n",
    "        theta=labels,\n",
    "        fill='toself',\n",
    "        name=city\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            visible=True,\n",
    "            range=[0, 100]\n",
    "        )),\n",
    "    showlegend=True,\n",
    "    title=\"Comparison of Top 5 Cities Across All Factors\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. City Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's cluster cities based on their characteristics\n",
    "# This can help identify cities with similar profiles\n",
    "\n",
    "# Prepare data for clustering\n",
    "cluster_data = scores_df[radar_cols].copy()\n",
    "\n",
    "# Normalize the data for clustering\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(cluster_data)\n",
    "\n",
    "# Determine optimal number of clusters using the elbow method\n",
    "inertia = []\n",
    "k_range = range(1, min(10, len(df)))\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(scaled_data)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, inertia, 'bx-')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Choose number of clusters (can be adjusted based on the elbow curve)\n",
    "n_clusters = 4  # Example value, adjust based on the elbow plot\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Add cluster assignments to the dataframe\n",
    "scores_df['cluster'] = clusters\n",
    "\n",
    "# Analyze clusters\n",
    "cluster_profiles = scores_df.groupby('cluster')[radar_cols].mean()\n",
    "print(\"Cluster Profiles:\")\n",
    "print(cluster_profiles)\n",
    "\n",
    "# Create interpretable cluster names based on their characteristics\n",
    "cluster_names = []\n",
    "for i in range(n_clusters):\n",
    "    profile = cluster_profiles.iloc[i]\n",
    "    \n",
    "    # Find the top 2 strengths of this cluster\n",
    "    strengths = profile.nlargest(2).index.tolist()\n",
    "    strength_names = [s.replace('_', ' ').title().replace('Score', '').replace('Index', '').strip() for s in strengths]\n",
    "    \n",
    "    name = f\"Cluster {i+1}: {' & '.join(strength_names)}\"\n",
    "    cluster_names.append(name)\n",
    "\n",
    "# Display cities by cluster\n",
    "for i in range(n_clusters):\n",
    "    cities_in_cluster = scores_df[scores_df['cluster'] == i]['city'].tolist()\n",
    "    print(f\"\\n{cluster_names[i]}:\")\n",
    "    print(\", \".join(cities_in_cluster))\n",
    "\n",
    "# Visualize clusters with PCA for dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "pca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'])\n",
    "pca_df['city'] = scores_df['city'].values\n",
    "pca_df['cluster'] = clusters\n",
    "\n",
    "# Plot clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='cluster', data=pca_df, palette='viridis', s=100)\n",
    "\n",
    "# Add city labels\n",
    "for i, row in pca_df.iterrows():\n",
    "    plt.text(row['PC1']+0.02, row['PC2']+0.02, row['city'], fontsize=9)\n",
    "\n",
    "plt.title('City Clusters Based on Remote Work Factors')\n",
    "plt.legend(title='Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Interactive Ranking Tool with Custom Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive function to let the user adjust weights based on their preferences\n",
    "from ipywidgets import interact, FloatSlider, HBox, VBox, Output, Label, interactive_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "out = Output()\n",
    "\n",
    "# Available factors for weighting\n",
    "available_factors = [factor for factor in score_columns if factor in scores_df.columns]\n",
    "\n",
    "# Create sliders for each factor\n",
    "sliders = {}\n",
    "for factor in available_factors:\n",
    "    display_name = factor.replace('_', ' ').title().replace('Score', '').replace('Index', '')\n",
    "    sliders[factor] = FloatSlider(\n",
    "        value=default_weights.get(factor, 0.1),\n",
    "        min=0,\n",
    "        max=1,\n",
    "        step=0.05,\n",
    "        description=display_name,\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "        orientation='horizontal',\n",
    "        readout=True,\n",
    "        readout_format='.2f',\n",
    "        layout=widgets.Layout(width='70%')\n",
    "    )\n",
    "\n",
    "# Function to update rankings based on slider values\n",
    "def update_rankings(**kwargs):\n",
    "    # Create weights dictionary from slider values\n",
    "    custom_weights = kwargs\n",
    "    \n",
    "    # Normalize weights to sum to 1\n",
    "    total = sum(custom_weights.values())\n",
    "    if total > 0:  # Avoid division by zero\n",
    "        normalized_weights = {k: v/total for k, v in custom_weights.items()}\n",
    "    else:\n",
    "        normalized_weights = {k: 1/len(custom_weights) for k in custom_weights.keys()}\n",
    "    \n",
    "    # Calculate custom weighted scores\n",
    "    custom_ranking = calculate_weighted_score(scores_df, normalized_weights)\n",
    "    \n",
    "    # Sort by total score\n",
    "    sorted_ranking = custom_ranking.sort_values('total_score', ascending=False)[['city', 'total_score']]\n",
    "    \n",
    "    # Clear previous output\n",
    "    out.clear_output()\n",
    "    \n",
    "    # Display rankings\n",
    "    with out:\n",
    "        print(\"Custom Rankings - Best Cities for Remote Work in Brazil:\")\n",
    "        print(sorted_ranking)\n",
    "        \n",
    "        # Create bar chart for visualization\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        top10 = sorted_ranking.head(10)\n",
    "        sns.barplot(x='total_score', y='city', data=top10)\n",
    "        plt.title('Top 10 Cities for Remote Work in Brazil (Custom Weights)')\n",
    "        plt.xlabel('Total Score')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Create the interactive widget\n",
    "interactive_plot = interactive_output(update_rankings, sliders)\n",
    "\n",
    "# Labels and instructions\n",
    "title = widgets.HTML(\"<h3>Customize Your Weights for City Ranking</h3>\")\n",
    "instructions = widgets.HTML(\"<p>Adjust the sliders to set your preferences for each factor. The total will be normalized automatically.</p>\")\n",
    "\n",
    "# Display the interactive tool\n",
    "display(title)\n",
    "display(instructions)\n",
    "display(VBox([*sliders.values()]))\n",
    "display(out)\n",
    "\n",
    "# Initialize with default weights\n",
    "update_rankings(**{factor: sliders[factor].value for factor in available_factors})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. City Profiles: Detailed Look at Top Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed profiles for the top 3 cities\n",
    "top3_cities = final_ranking.head(3)['city'].tolist()\n",
    "\n",
    "for city in top3_cities:\n",
    "    # Get all data for this city\n",
    "    city_data = df[df['city'] == city].iloc[0]\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Detailed Profile: {city}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Internet Quality\n",
    "    print(\"\\nüåê Internet Quality:\")\n",
    "    internet_cols = [col for col in df.columns if col.startswith('internet_') and not col.endswith('_score')]\n",
    "    for col in internet_cols:\n",
    "        if col in city_data:\n",
    "            display_name = col.replace('internet_', '').replace('_', ' ').title()\n",
    "            value = city_data[col]\n",
    "            if 'mbps' in col.lower():\n",
    "                print(f\"  - {display_name}: {value:.1f} Mbps\")\n",
    "            elif 'availability' in col.lower():\n",
    "                print(f\"  - {display_name}: {value*100:.1f}%\")\n",
    "            else:\n",
    "                print(f\"  - {display_name}: {value}\")\n",
    "    \n",
    "    # Cost of Living\n",
    "    print(\"\\nüí∞ Cost of Living:\")\n",
    "    cost_cols = [col for col in df.columns if col.startswith('cost_') and not col.endswith('_score')]\n",
    "    for col in cost_cols:\n",
    "        if col in city_data:\n",
    "            display_name = col.replace('cost_', '').replace('_', ' ').title()\n",
    "            value = city_data[col]\n",
    "            if 'price' in col.lower() or 'rent' in col.lower() or 'monthly' in col.lower():\n",
    "                print(f\"  - {display_name}: R$ {value:.2f}\")\n",
    "            else:\n",
    "                print(f\"  - {display_name}: {value}\")\n",
    "    \n",
    "    # Safety\n",
    "    print(\"\\nüõ°Ô∏è Safety:\")\n",
    "    safety_cols = [col for col in df.columns if col.startswith('safety_') and not col.endswith('_index')]\n",
    "    for col in safety_cols:\n",
    "        if col in city_data:\n",
    "            display_name = col.replace('safety_', '').replace('_', ' ').title()\n",
    "            value = city_data[col]\n",
    "            if 'rate' in col.lower():\n",
    "                print(f\"  - {display_name}: {value:.2f} per 100k\")\n",
    "            elif 'perceived' in col.lower():\n",
    "                print(f\"  - {display_name}: {value:.1f}%\")\n",
    "            else:\n",
    "                print(f\"  - {display_name}: {value}\")\n",
    "    \n",
    "    # Climate\n",
    "    print(\"\\n‚òÄÔ∏è Climate:\")\n",
    "    climate_cols = [col for col in df.columns if col.startswith('climate_') and not col.endswith('_index')]\n",
    "    for col in climate_cols:\n",
    "        if col in city_data:\n",
    "            display_name = col.replace('climate_', '').replace('_', ' ').title()\n",
    "            value = city_data[col]\n",
    "            if 'temp' in col.lower():\n",
    "                print(f\"  - {display_name}: {value:.1f}¬∞C\")\n",
    "            elif 'rainfall' in col.lower():\n",
    "                print(f\"  - {display_name}: {value:.0f}mm\")\n",
    "            elif 'humidity' in col.lower():\n",
    "                print(f\"  - {display_name}: {value:.1f}%\")\n",
    "            else:\n",
    "                print(f\"  - {display_name}: {value}\")\n",
    "    \n",
    "    # Coworking\n",
    "    print(\"\\nüíº Coworking Spaces:\")\n",
    "    coworking_cols = [col for col in df.columns if col.startswith('coworking_') and not col.endswith('_score')]\n",
    "    for col in coworking_cols:\n",
    "        if col in city_data and not col.endswith('spaces'):\n",
    "            display_name = col.replace('coworking_', '').replace('_', ' ').title()\n",
    "            value = city_data[col]\n",
    "            if 'price' in col.lower():\n",
    "                print(f\"  - {display_name}: R$ {value:.2f}\")\n",
    "            else:\n",
    "                print(f\"  - {display_name}: {value}\")\n",
    "    \n",
    "    # Transportation\n",
    "    print(\"\\nüöå Transportation:\")\n",
    "    transport_cols = [col for col in df.columns if col.startswith('transport_') and not col.endswith('_score')]\n",
    "    for col in transport_cols:\n",
    "        if col in city_data:\n",
    "            display_name = col.replace('transport_', '').replace('_', ' ').title()\n",
    "            value = city_data[col]\n",
    "            if isinstance(value, bool):\n",
    "                print(f\"  - {display_name}: {'Yes' if value else 'No'}\")\n",
    "            elif 'time' in col.lower():\n",
    "                print(f\"  - {display_name}: {value} minutes\")\n",
    "            elif 'distance' in col.lower():\n",
    "                print(f\"  - {display_name}: {value} km\")\n",
    "            else:\n",
    "                print(f\"  - {display_name}: {value}\")\n",
    "    \n",
    "    # Quality of Life\n",
    "    print(\"\\nüåü Quality of Life:\")\n",
    "    quality_cols = [col for col in df.columns if col.startswith('quality_') and not col.endswith('_score')]\n",
    "    for col in quality_cols:\n",
    "        if col in city_data:\n",
    "            display_name = col.replace('quality_', '').replace('_', ' ').title()\n",
    "            value = city_data[col]\n",
    "            if 'index' in col.lower():\n",
    "                print(f\"  - {display_name}: {value:.1f}/10\")\n",
    "            elif 'hdi' in col.lower():\n",
    "                print(f\"  - {display_name}: {value:.3f}\")\n",
    "            elif 'spaces' in col.lower():\n",
    "                print(f\"  - {display_name}: {value:.1f} m¬≤\")\n",
    "            else:\n",
    "                print(f\"  - {display_name}: {value:.1f}\")\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings\n",
    "\n",
    "From our analysis of the best cities for remote work in Brazil, we've discovered:\n",
    "\n",
    "1. **Top Cities Overall**: The data shows that [top cities from ranking] are the best overall choices for remote workers in Brazil when considering all factors. These cities offer the optimal balance of internet quality, affordability, safety, and quality of life.\n",
    "\n",
    "2. **City Clusters**: We identified distinct city profiles that cater to different remote worker needs:\n",
    "   - Digital Nomad Havens: Cities with excellent internet and abundant coworking spaces\n",
    "   - Budget-Friendly Options: Cities with lower cost of living but decent infrastructure\n",
    "   - Family-Friendly Locations: Cities with high safety ratings and quality of life\n",
    "   - Balanced All-Rounders: Cities that score reasonably well across all categories\n",
    "\n",
    "3. **Internet Infrastructure**: [Top internet cities] offer the best connectivity, which is essential for remote work. These cities have average download speeds exceeding [X] Mbps and high fiber availability.\n",
    "\n",
    "4. **Cost-Effectiveness**: For budget-conscious remote workers, [affordable cities] provide the best value, with significantly lower housing costs and general expenses.\n",
    "\n",
    "5. **Safety Considerations**: [Safest cities] stand out with low crime rates and high perceived safety, making them ideal for those prioritizing security.\n",
    "\n",
    "6. **Climate Comfort**: [Best climate cities] offer the most comfortable year-round climate for remote workers who value pleasant working conditions.\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "Based on our analysis, we recommend:\n",
    "\n",
    "1. **For Digital Nomads**: Prioritize cities with high internet quality scores and abundant coworking spaces, such as [relevant cities].\n",
    "\n",
    "2. **For Long-term Relocation**: Consider cities with high quality of life scores and safety ratings, such as [relevant cities].\n",
    "\n",
    "3. **For Budget-conscious Workers**: Focus on cities with favorable cost of living scores that still maintain decent internet infrastructure, such as [relevant cities].\n",
    "\n",
    "4. **For Families**: Prioritize cities with high safety scores, good healthcare, and educational opportunities, such as [relevant cities].\n",
    "\n",
    "### Future Analysis Opportunities\n",
    "\n",
    "To enhance this study further, we could:\n",
    "\n",
    "1. Collect more granular data on neighborhood-level metrics within each city\n",
    "2. Add data on remote work communities and networking opportunities\n",
    "3. Consider visa and residency requirements for international remote workers\n",
    "4. Analyze seasonal variations in climate and tourism patterns\n",
    "5. Include more qualitative data from interviews with current remote workers in each city\n",
    "\n",
    "This analysis provides a data-driven framework for remote workers to select the Brazilian city that best matches their personal and professional priorities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
